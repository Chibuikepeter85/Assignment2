{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from IPython.display import display, Image as IPImage\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for train, validation, and test datasets\n",
    "TRAIN_PATH = r\"/work/TALC/enel645_2024f/garbage_data/CVPR_2024_dataset_Train\"\n",
    "VAL_PATH = r\"/work/TALC/enel645_2024f/garbage_data/CVPR_2024_dataset_Val\"\n",
    "TEST_PATH = r\"/work/TALC/enel645_2024f/garbage_data/CVPR_2024_dataset_Test\"\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"Red\", \"Blue\", \"Black\", \"TTR\"]\n",
    "\n",
    "\n",
    "# Pre-process the data\n",
    "# Transformations for the images\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet statistics\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for the images\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet statistics\n",
    "])\n",
    "\n",
    "# Custom dataset class for loading images and text\n",
    "class CustomImageTextDataset(Dataset):\n",
    "    def __init__(self, image_dir, tokenizer, max_len, image_transform=None):\n",
    "        self.image_paths = []\n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.image_transform = image_transform\n",
    "\n",
    "        class_folders = sorted(os.listdir(image_dir))\n",
    "        label_map = {class_name: idx for idx, class_name in enumerate(class_folders)}\n",
    "        self.label_map = label_map\n",
    "\n",
    "        for class_name in class_folders:\n",
    "            class_path = os.path.join(image_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for file_name in os.listdir(class_path):\n",
    "                    if file_name.endswith(('.png', '.jpg')):\n",
    "                        image_path = os.path.join(class_path, file_name)\n",
    "                        self.image_paths.append(image_path)\n",
    "                        text_label = os.path.splitext(file_name)[0].replace('_', ' ')\n",
    "                        self.texts.append(text_label)\n",
    "                        self.labels.append(label_map[class_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "max_len = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets and split data\n",
    "train_dataset = CustomImageTextDataset(image_dir=TRAIN_PATH, tokenizer=tokenizer, max_len=max_len, image_transform=image_transform)\n",
    "val_dataset = CustomImageTextDataset(image_dir=VAL_PATH, tokenizer=tokenizer, max_len=max_len, image_transform=image_transform)\n",
    "test_dataset = CustomImageTextDataset(image_dir=TEST_PATH, tokenizer=tokenizer, max_len=max_len, image_transform=image_transform)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Transfer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GarbageModel(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape=(3, 224, 224), transfer=False):\n",
    "        super(GarbageModel, self).__init__()\n",
    "\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.text_out = nn.Linear(self.distilbert.config.hidden_size, 128)\n",
    "\n",
    "        self.feature_extractor = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if transfer else None)\n",
    "\n",
    "        if transfer:\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        n_image_features = self._get_conv_output(input_shape)\n",
    "        self.image_classifier = nn.Linear(n_image_features, 128)\n",
    "        self.classifiermain = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "        output_feat = self.feature_extractor(tmp_input)\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        text_features = self.distilbert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0]\n",
    "        text_features = self.drop(text_features)\n",
    "        text_features = self.text_out(text_features)\n",
    "\n",
    "        image_features = self.feature_extractor(images)\n",
    "        image_features = image_features.view(image_features.size(0), -1)\n",
    "        image_features = self.image_classifier(image_features)\n",
    "\n",
    "        combined_features = torch.cat((text_features, image_features), dim=1)\n",
    "        output = self.classifiermain(combined_features)\n",
    "        return output\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = len(train_dataset.label_map)\n",
    "model = GarbageModel(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and metrics setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and validation loop Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                outputs = model(images, input_ids, attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}, Val Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with confusion matrix and metrics Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    sensitivity = recall_score(all_labels, all_preds, average='macro')\n",
    "    specificity = precision_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(result.history[\"accuracy\"])\n",
    "    plt.show()\n",
    "    plt.title(\"sensitivity\")\n",
    "    plt.plot(result.history[\"sensitivity\"])\n",
    "    plt.show()\n",
    "\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean color distribution and class distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and display mean color distribution and class distribution\n",
    "def plot_distributions(dataset, title_prefix):\n",
    "    # Calculate color distributions\n",
    "    color_distributions = []\n",
    "    class_counts = {label: 0 for label in dataset.label_map.keys()}\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        data = dataset[i]\n",
    "        img = data['image'].numpy().transpose(1, 2, 0)  # Convert to HWC for histogram\n",
    "        label = list(dataset.label_map.keys())[data['label'].item()]\n",
    "\n",
    "        # Calculate histogram for each color channel and sum up\n",
    "        hist_r, _ = np.histogram(img[:, :, 0], bins=256, range=(0, 1))\n",
    "        hist_g, _ = np.histogram(img[:, :, 1], bins=256, range=(0, 1))\n",
    "        hist_b, _ = np.histogram(img[:, :, 2], bins=256, range=(0, 1))\n",
    "        color_distributions.append(hist_r + hist_g + hist_b)\n",
    "\n",
    "        # Count class occurrences\n",
    "        class_counts[label] += 1\n",
    "\n",
    "    # Mean color distribution\n",
    "    mean_color_distribution = np.mean(color_distributions, axis=0)\n",
    "\n",
    "    # Plot distributions\n",
    "    fig, a = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Mean color distribution plot\n",
    "    a[0].bar(np.arange(256), mean_color_distribution)\n",
    "    a[0].set_title(f\"{title_prefix} Mean Color Distribution\")\n",
    "    a[0].set_xlabel(\"Color Value\")\n",
    "    a[0].set_ylabel(\"Number of Pixels\")\n",
    "\n",
    "    # Class distribution plot\n",
    "    a[1].bar(class_counts.keys(), class_counts.values())\n",
    "    a[1].set_title(f\"{title_prefix} Class Distribution\")\n",
    "    a[1].set_xlabel(\"Classes\")\n",
    "    a[1].set_ylabel(\"Number of Images\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot distributions for train, validation, and test datasets\n",
    "plot_distributions(train_dataset, \"Train Set\")\n",
    "plot_distributions(val_dataset, \"Validation Set\")\n",
    "plot_distributions(test_dataset, \"Test Set\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
